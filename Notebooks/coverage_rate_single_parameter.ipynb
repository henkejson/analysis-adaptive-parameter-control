{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63539aa876a44ffb8af42187f67560da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=2.0, description='Sigma_alpha (sigma_a):', max=6.0, min=0.5), FloatSliâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.calc_prior_dist(s_a, s_b, s_g, a_bar_mu, a_bar_sigma, max_theta)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymc as pm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from ipywidgets import interact, FloatSlider\n",
    "from utils.prior_check_helper import HistogramPlot, plot_histograms\n",
    "\n",
    "def calc_prior_dist(s_a, s_b, s_g, a_bar_mu, a_bar_sigma, max_theta):\n",
    "    with pm.Model() as model:\n",
    "        # Global Intercept and standard deviation for Modules\n",
    "        a_bar = pm.Normal('a_bar', mu=a_bar_mu, sigma=a_bar_sigma)\n",
    "        \n",
    "        # Standard Deviations for Modules, Parameters and Interactions\n",
    "        sigma_a = pm.Exponential('sigma_a', s_a)\n",
    "        sigma_b = pm.Exponential('sigma_b', s_b)\n",
    "        sigma_g = pm.Exponential('sigma_g', s_g)\n",
    "        \n",
    "        # Non-centered parameterizations for module, parameter and interaction effect.\n",
    "        a_offset = pm.Normal('a_offset', mu=0, sigma=1)\n",
    "        a_m = pm.Deterministic('a_m', a_bar + sigma_a * a_offset)\n",
    "\n",
    "        b_offset = pm.Normal('b_offset', mu=0, sigma=1)\n",
    "        b_p = pm.Deterministic('b_p', sigma_b * b_offset)\n",
    "\n",
    "        g_offset = pm.Normal('g_offset', mu=0, sigma=1)\n",
    "        g_mp = pm.Deterministic('g_mp', sigma_g * g_offset)\n",
    "        \n",
    "        pm.Deterministic('p_before', (a_m + b_p + g_mp))\n",
    "\n",
    "        # Link function (logit), unbounded to (0,1) probability\n",
    "        pm.Deterministic('p', pm.math.sigmoid(a_m + b_p + g_mp))\n",
    "        \n",
    "        # Beta distribution likelihood \n",
    "        pm.Uniform('theta', 10, max_theta) # Disperion parameter\n",
    "\n",
    "        # Sample Priors\n",
    "        idata = pm.sample_prior_predictive(samples=10000)\n",
    "\n",
    "\n",
    "    # Fetch and flatten priors\n",
    "    prior_p = idata.prior['p'].values.flatten()\n",
    "    prior_theta = idata.prior['theta'].values.flatten()\n",
    "\n",
    "\n",
    "    # Sample one data point from each combination\n",
    "    simulated_observations = np.random.beta(a=prior_p * prior_theta, b=(1 - prior_p) * prior_theta)\n",
    "\n",
    "\n",
    "    #Predicated observations\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    observation_plot = HistogramPlot(simulated_observations,'Simulated Observations of Coverage using priors ', 'Values',\n",
    "                                        'darkcyan', bin_range=(0, 1.05))\n",
    "    observation_plot.plot()\n",
    "\n",
    "\n",
    "    plots = [\n",
    "        HistogramPlot(idata.prior['p_before'].values.flatten(), 'Prior Distribution of p - Logistic / Inverse Logit', 'p', 'black'),\n",
    "        HistogramPlot(idata.prior['p'].values.flatten(), 'Prior Distribution of p - Logistic / Inverse Logit', 'p', 'purple', bin_range=(0, 1), bins=20),\n",
    "        HistogramPlot(idata.prior['theta'].values.flatten(), 'Prior Distribution of theta - Uniform(10,200)', 'p_before', 'orange'),\n",
    "        HistogramPlot(idata.prior['a_bar'].values.flatten(), 'Prior Distribution of a_bar - Normal(0, 1.5)', 'a_bar', 'blue'),\n",
    "        HistogramPlot(idata.prior['sigma_a'].values.flatten(), 'Prior Distribution of sigma - Exponential(1.5)', 'sigma', 'red'),\n",
    "        HistogramPlot(idata.prior['a_m'].values.flatten(), 'Prior Distribution of a_m - Normal(a_bar, sigma)', 'a_m', 'green'),\n",
    "        HistogramPlot(idata.prior['sigma_b'].values.flatten(), 'Prior Distribution of sigma - Exponential(1.5)', 'sigma', 'salmon'),\n",
    "        HistogramPlot(idata.prior['b_p'].values.flatten(), 'Prior Distribution of b_p - Normal(a_bar, sigma)', 'b_p', 'pink'),\n",
    "        HistogramPlot(idata.prior['sigma_g'].values.flatten(), 'Prior Distribution of sigma - Exponential(1.5)', 'sigma', 'brown'),\n",
    "        HistogramPlot(idata.prior['g_mp'].values.flatten(), 'Prior Distribution of b_p - Normal(a_bar, sigma)', 'g_mp', 'yellow')\n",
    "    ]\n",
    "\n",
    "    plot_histograms(plots, 5, 2, figsize=(10,20))\n",
    "\n",
    "\n",
    "s_a = FloatSlider(value=2, min=0.5, max=6, step=0.1, description='Sigma_alpha (sigma_a):')\n",
    "s_b = FloatSlider(value=5, min=0.5, max=6, step=0.1, description='Sigma_beta (sigma_b):')\n",
    "s_g = FloatSlider(value=5, min=0.5, max=6, step=0.1, description='Sigma_gamma (sigma_g):')\n",
    "a_bar_mu = FloatSlider(value=0, min=-2, max=2, step=0.1, description='alpha bar mu (a_bar_mu):')\n",
    "a_bar_sigma = FloatSlider(value=1.5, min=0, max=3, step=0.1, description='alpha bar sigma (a_bar_sigma):')\n",
    "max_theta = FloatSlider(value=200, min=20, max=200, step=0.1, description='max bar sigma (a_bar_sigma):')\n",
    "\n",
    "\n",
    "\n",
    "# Interactive sliders\n",
    "interact(calc_prior_dist, s_a=s_a, s_b=s_b, s_g=s_g, a_bar_mu=a_bar_mu, a_bar_sigma=a_bar_sigma, max_theta=max_theta)\n",
    "#calc_prior_dist(2, 5, 5, 0, 1.5, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the CSV file\n",
    "data = pd.read_csv(\"../single_parameter/combined_data/statistics.csv\")\n",
    "\n",
    "# Select columns for the coverage timeline\n",
    "coverage_data = data.filter(regex='^CoverageTimeline_T')\n",
    "\n",
    "# Calculate the integral for each row using the trapezoidal rule\n",
    "data['IntegralValue'] = coverage_data.apply(lambda row: np.trapz(row, dx=1), axis=1)\n",
    "data['IntegralValue'] = data['IntegralValue'] / 300.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import formulaic\n",
    "import pymc as pm\n",
    "import pandas as pd\n",
    "\n",
    "#data = pd.read_csv(\"../../single_parameter/combined_data/statistics.csv\")\n",
    "\n",
    "# Dummy variables for Module and Parameters\n",
    "model_formula = 'IntegralValue ~ 0 + C(TargetModule) + C(TuningParameters, contr.treatment(\"NONE\"))'\n",
    "design_matrix = formulaic.model_matrix(model_formula, data=data)\n",
    "\n",
    "module_matrix = design_matrix.rhs.iloc[:, :24]\n",
    "parameter_matrix = design_matrix.rhs.iloc[:, 24:]\n",
    "\n",
    "# Dummy variables for interaction terms\n",
    "model_formula = 'IntegralValue ~ 0 + C(TargetModule) : C(TuningParameters)'\n",
    "design_matrix = formulaic.model_matrix(model_formula, data=data)\n",
    "\n",
    "# Filter out columns that contain 'T.NONE' in their name\n",
    "columns_to_drop = [col for col in design_matrix.rhs.columns if 'T.NONE' in col]\n",
    "\n",
    "# Drop the identified columns\n",
    "design_matrix.rhs.drop(columns=columns_to_drop, axis=1, inplace=True)\n",
    "interaction_matrix = design_matrix.rhs.iloc[:,:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    # Global Intercept and standard deviation for Modules\n",
    "    a_bar = pm.Normal('a_bar', mu=0, sigma=1.5)\n",
    "    \n",
    "    # Standard Deviations for Modules, Parameters and Interactions\n",
    "    sigma_a = pm.Exponential('sigma_a', 2.0)\n",
    "    sigma_b = pm.Exponential('sigma_b', 5.0)\n",
    "    sigma_g = pm.Exponential('sigma_g', 5.0)\n",
    "    \n",
    "    # Non-centered parameterizations\n",
    "    a_offset = pm.Normal('a_offset', mu=0, sigma=1, shape=24)\n",
    "    a_m = pm.Deterministic('a_m', a_bar + sigma_a * a_offset)\n",
    "\n",
    "    b_offset = pm.Normal('b_offset', mu=0, sigma=1, shape=12)\n",
    "    b_p = pm.Deterministic('b_p', sigma_b * b_offset)\n",
    "\n",
    "    g_offset = pm.Normal('g_offset', mu=0, sigma=1, shape=288)\n",
    "    g_mp = pm.Deterministic('g_mp', sigma_g * g_offset)\n",
    "\n",
    "    \n",
    "    # Activate the correct dummy variables\n",
    "    logit_a = pm.math.dot(module_matrix, a_m)\n",
    "    logit_b = pm.math.dot(parameter_matrix, b_p)\n",
    "    logit_g = pm.math.dot(interaction_matrix, g_mp)\n",
    "\n",
    "    # Link function (logit), unbounded to (0,1) probability\n",
    "    p = pm.Deterministic('p', pm.math.sigmoid(logit_a + logit_b + logit_g))\n",
    "    \n",
    "    # Beta distribution likelihood \n",
    "    theta = pm.Uniform('theta', 10, 200) # Disperion parameter\n",
    "    Y_obs = pm.Beta('Y_obs', alpha=p*theta, beta=(1-p)*theta, observed=design_matrix.lhs['IntegralValue'])\n",
    "    \n",
    "    # Sample from the model\n",
    "    trace = pm.sample(1000, chains=4,return_inferencedata=True, progressbar=True, target_accept=0.95)\n",
    "    log_lik = pm.compute_log_likelihood(trace)\n",
    "    \n",
    "print(\"Model building complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
